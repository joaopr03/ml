{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8d1ab1-3a5f-48e1-973e-f20cd63ffe96",
   "metadata": {},
   "source": [
    "# Import the Dataset and Explore the Data <a name=\"import-the-dataset-and-explore-the-data\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2c4a3-32c6-4bb2-8736-1e8f4a5f7d0d",
   "metadata": {},
   "source": [
    "## 1.1 Importing Libraries <a name=\"11-importing-libraries\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8102a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\mainj\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\mainj\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mainj\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd838a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\mainj\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\mainj\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mainj\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71989db3-e70e-498d-b70e-1ce526d0cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c33277-dc17-4253-8111-87f2f14440e9",
   "metadata": {},
   "source": [
    "## Loading the previous Datasets <a name=\"12-loading-and-reading-the-dataset\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1cca85d-d482-491c-a83c-fab62ebbcf02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_nb2.csv', index_col=0)\n",
    "X_val = pd.read_csv('X_val_nb2.csv', index_col=0)\n",
    "X_test = pd.read_csv('X_test_nb2.csv', index_col=0)\n",
    "X_test_original = pd.read_csv('test_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4809bbf-f751-42fb-8c97-cf847e9e050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"y_train_nb2.csv\", index_col=0)\n",
    "y_val = pd.read_csv(\"y_val.csv\", index_col=0)\n",
    "#uploading it as a 1-column dataframe while preserving its index, to make sure it aligns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e449648-bd13-40ad-ae10-e25a81a512b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.iloc[:, 0]\n",
    "y_val = y_val.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b883d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_predictions(y_pred_test, X_test_original, filename=\"final_submission.csv\"):\n",
    "    \n",
    "    # Convert predictions to a pandas Series and ensure integer type\n",
    "    y_pred_test = pd.Series(y_pred_test)\n",
    "\n",
    "    y_pred_test = y_pred_test.astype(int)\n",
    "    \n",
    "    # Replace prediction codes with their corresponding labels\n",
    "    y_pred_test = y_pred_test.replace({\n",
    "        1: '1. CANCELLED',\n",
    "        2: '2. NON-COMP',\n",
    "        3: '3. MED ONLY',\n",
    "        4: '4. TEMPORARY',\n",
    "        5: '5. PPD SCH LOSS',\n",
    "        6: '6. PPD NSL',\n",
    "        7: '7. PTD',\n",
    "        8: '8. DEATH'\n",
    "    })\n",
    "    \n",
    "    X_test_original = X_test_original.reset_index(drop=True)\n",
    "    y_pred_test = y_pred_test.reset_index(drop=True)\n",
    "    \n",
    "    # Combine 'Claim Identifier' and predictions into a new DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'Claim Identifier': X_test_original['Claim Identifier'],\n",
    "        'Claim Injury Type': y_pred_test\n",
    "    })\n",
    "    \n",
    "    # Export to CSV\n",
    "    submission.to_csv(filename, index=False)\n",
    "    print(f\"File exported successfully as {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0446885-4903-479f-b063-34e997ad3f79",
   "metadata": {},
   "source": [
    "# 6. Model Assessment and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304f9f4-58ef-45b5-a42e-f138dccccbfc",
   "metadata": {},
   "source": [
    "## 6.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbcdc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and F1-Score for each class:\n",
      "Class 1:\n",
      "  Precision: 0.36\n",
      "  Recall: 0.63\n",
      "  F1-Score: 0.45\n",
      "Class 2:\n",
      "  Precision: 0.86\n",
      "  Recall: 0.86\n",
      "  F1-Score: 0.86\n",
      "Class 3:\n",
      "  Precision: 0.31\n",
      "  Recall: 0.23\n",
      "  F1-Score: 0.27\n",
      "Class 4:\n",
      "  Precision: 0.75\n",
      "  Recall: 0.60\n",
      "  F1-Score: 0.66\n",
      "Class 5:\n",
      "  Precision: 0.51\n",
      "  Recall: 0.79\n",
      "  F1-Score: 0.62\n",
      "Class 6:\n",
      "  Precision: 0.11\n",
      "  Recall: 0.33\n",
      "  F1-Score: 0.17\n",
      "Class 7:\n",
      "  Precision: 0.02\n",
      "  Recall: 0.07\n",
      "  F1-Score: 0.03\n",
      "Class 8:\n",
      "  Precision: 0.13\n",
      "  Recall: 0.66\n",
      "  F1-Score: 0.22\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestClassifier model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,  # Increase the number of trees\n",
    "    max_depth=20,  # Limit the maximum depth of the trees\n",
    "    min_samples_split=5,  # Set the minimum number of samples required to split a node\n",
    "    min_samples_leaf=2,  # Set the minimum number of samples in a leaf\n",
    "    max_features='sqrt',  # Limit the number of features considered at each split\n",
    "    class_weight='balanced',  # Adjust weights to handle imbalanced classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "# Extract only precision, recall, and F1-score\n",
    "print(\"Precision, Recall, and F1-Score for each class:\")\n",
    "for label, metrics in class_report.items():\n",
    "    if label.isdigit():  # Ensure we only print class-related metrics\n",
    "        print(f\"Class {label}:\")\n",
    "        print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "        print(f\"  F1-Score: {metrics['f1-score']:.2f}\")\n",
    "        \n",
    "test_results = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa5131f-9352-4d77-8a37-00a3ce2b5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3804"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_precision = precision_score(y_val, y_pred, average='macro').round(4)\n",
    "rf_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a003fd7-2a0a-4e7c-bebb-6c9de01fbada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_recall = recall_score(y_val, y_pred, average='macro').round(4)\n",
    "rf_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7547c531-15a0-426c-aaee-c957fd003bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4095"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_f1 = f1_score(y_val, y_pred, average='macro').round(4)\n",
    "rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dede2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as rf_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"rf_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367b8b2-790d-4d43-bb66-0f24f1854849",
   "metadata": {},
   "source": [
    "## 6.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e310833d-1aad-40a0-bc58-24e9ad621e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(\n",
    "    solver='saga',         # Efficient solver for large datasets\n",
    "    multi_class='multinomial',  # Better for multi-class problems\n",
    "    penalty='l2',          # Use L2 regularization\n",
    "    C=1.0,                 # Default regularization strength\n",
    "    max_iter=500,          # Increase max iterations\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    n_jobs=-1,             # Use all CPU cores for computation\n",
    "    random_state=42,       # Reproducibility\n",
    "    verbose=1              # Monitor training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065b1e81-4e68-4e8e-8424-6d5d6d196c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 64 epochs took 20 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=500,\n",
       "                   multi_class=&#x27;multinomial&#x27;, n_jobs=-1, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=500,\n",
       "                   multi_class=&#x27;multinomial&#x27;, n_jobs=-1, random_state=42,\n",
       "                   solver=&#x27;saga&#x27;, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=500,\n",
       "                   multi_class='multinomial', n_jobs=-1, random_state=42,\n",
       "                   solver='saga', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77e3b85-9b94-43eb-aeb6-e988265eef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = log_model.predict(X_train)\n",
    "y_pred = log_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84006980-be05-4985-ad7c-19ff68022d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2877"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_precision = precision_score(y_val, y_pred, average='macro').round(4)\n",
    "log_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9902bf-6cbc-436b-bd26-1cd1dc45764a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5224"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_recall = recall_score(y_val, y_pred, average='macro').round(4)\n",
    "log_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a28672-c7bf-4265-940f-049e5229c17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_f1 = f1_score(y_val, y_pred, average='macro').round(4)\n",
    "log_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887b259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7da2255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as log_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"log_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d5fdb",
   "metadata": {},
   "source": [
    "## 6.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd35305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and F1-Score for each class (Decision Tree):\n",
      "Class 1:\n",
      "  Precision: 0.26\n",
      "  Recall: 0.49\n",
      "  F1-Score: 0.34\n",
      "Class 2:\n",
      "  Precision: 0.85\n",
      "  Recall: 0.74\n",
      "  F1-Score: 0.79\n",
      "Class 3:\n",
      "  Precision: 0.18\n",
      "  Recall: 0.31\n",
      "  F1-Score: 0.23\n",
      "Class 4:\n",
      "  Precision: 0.69\n",
      "  Recall: 0.51\n",
      "  F1-Score: 0.59\n",
      "Class 5:\n",
      "  Precision: 0.47\n",
      "  Recall: 0.57\n",
      "  F1-Score: 0.52\n",
      "Class 6:\n",
      "  Precision: 0.07\n",
      "  Recall: 0.19\n",
      "  F1-Score: 0.11\n",
      "Class 7:\n",
      "  Precision: 0.00\n",
      "  Recall: 0.00\n",
      "  F1-Score: 0.00\n",
      "Class 8:\n",
      "  Precision: 0.14\n",
      "  Recall: 0.37\n",
      "  F1-Score: 0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = dt_model.predict(X_val)\n",
    "\n",
    "# Generate classification report for Decision Tree\n",
    "class_report_dt = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "# Initialize variables to calculate the mean of precision, recall, and F1-score\n",
    "precision_sum, recall_sum, f1_score_sum, class_count = 0, 0, 0, 0\n",
    "\n",
    "print(\"Precision, Recall, and F1-Score for each class (Decision Tree):\")\n",
    "for label, metrics in class_report_dt.items():\n",
    "    if label.isdigit():  # Ensure we only process metrics for classes\n",
    "        precision_sum += metrics['precision']\n",
    "        recall_sum += metrics['recall']\n",
    "        f1_score_sum += metrics['f1-score']\n",
    "        class_count += 1\n",
    "        print(f\"Class {label}:\")\n",
    "        print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "        print(f\"  F1-Score: {metrics['f1-score']:.2f}\")\n",
    "        \n",
    "test_results = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e25a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3349"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_precision = round(precision_sum / class_count, 4)\n",
    "dt_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1072dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3986"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_recall = round(recall_sum / class_count, 4)\n",
    "dt_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b4ffa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3484"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_f1 = round(f1_score_sum / class_count, 4)\n",
    "dt_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33a93667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as dt_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"dt_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df396f3-d62f-4cc4-9eef-0c6cdf560728",
   "metadata": {},
   "source": [
    "## 6.4 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80eba880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mainj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mainj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mainj\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, and F1-Score for each class (Naive Bayes):\n",
      "Class 1:\n",
      "  Precision: 0.14\n",
      "  Recall: 0.52\n",
      "  F1-Score: 0.22\n",
      "Class 2:\n",
      "  Precision: 0.75\n",
      "  Recall: 0.81\n",
      "  F1-Score: 0.78\n",
      "Class 3:\n",
      "  Precision: 0.26\n",
      "  Recall: 0.08\n",
      "  F1-Score: 0.13\n",
      "Class 4:\n",
      "  Precision: 0.46\n",
      "  Recall: 0.10\n",
      "  F1-Score: 0.16\n",
      "Class 5:\n",
      "  Precision: 0.47\n",
      "  Recall: 0.27\n",
      "  F1-Score: 0.35\n",
      "Class 6:\n",
      "  Precision: 0.00\n",
      "  Recall: 0.00\n",
      "  F1-Score: 0.00\n",
      "Class 7:\n",
      "  Precision: 0.00\n",
      "  Recall: 0.97\n",
      "  F1-Score: 0.00\n",
      "Class 8:\n",
      "  Precision: 0.01\n",
      "  Recall: 0.44\n",
      "  F1-Score: 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the Naive Bayes model (Gaussian Naive Bayes for continuous features)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Fit the model to the training data\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = nb_model.predict(X_val)\n",
    "\n",
    "# Generate classification report for Naive Bayes\n",
    "class_report_nb = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "# Initialize variables to calculate the mean of precision, recall, and F1-score\n",
    "precision_sum, recall_sum, f1_score_sum, class_count = 0, 0, 0, 0\n",
    "\n",
    "print(\"Precision, Recall, and F1-Score for each class (Naive Bayes):\")\n",
    "for label, metrics in class_report_nb.items():\n",
    "    if label.isdigit():  # Ensure we only process metrics for classes\n",
    "        precision_sum += metrics['precision']\n",
    "        recall_sum += metrics['recall']\n",
    "        f1_score_sum += metrics['f1-score']\n",
    "        class_count += 1\n",
    "        print(f\"Class {label}:\")\n",
    "        print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "        print(f\"  F1-Score: {metrics['f1-score']:.2f}\")\n",
    "        \n",
    "test_results = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45be2c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2617"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_precision = round(precision_sum / class_count, 4)\n",
    "nb_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "930906a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3976"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_recall = round(recall_sum / class_count, 4)\n",
    "nb_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcdd43cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2069"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_f1 = round(f1_score_sum / class_count, 4)\n",
    "nb_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6556ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as nb_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"nb_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c2780-cd7f-4674-9466-280d0b780cf2",
   "metadata": {},
   "source": [
    "## 6.5 Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c33c985-a5b7-47db-a78a-afc127358648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.61\n",
      "Classification Report for Validation Set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.49      0.32      3743\n",
      "           2       0.79      0.85      0.82     87324\n",
      "           3       0.29      0.13      0.18     20672\n",
      "           4       0.64      0.38      0.48     44552\n",
      "           5       0.46      0.57      0.51     14484\n",
      "           6       0.05      0.53      0.10      1263\n",
      "           7       0.00      0.34      0.01        29\n",
      "           8       0.08      0.72      0.15       141\n",
      "\n",
      "    accuracy                           0.61    172208\n",
      "   macro avg       0.32      0.50      0.32    172208\n",
      "weighted avg       0.65      0.61      0.61    172208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model with your specifications\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(int(X_train.shape[1] * 0.8), int(X_train.shape[1] * 0.5)),  # 2 hidden layers with fewer neurons than features\n",
    "    activation='relu',  # ReLU activation function\n",
    "    solver='adam',      # Adam optimizer\n",
    "    learning_rate_init=0.01,  # Initial learning rate of 0.01\n",
    "    max_iter=500,       # Maximum number of iterations\n",
    "    random_state=42     # Ensures reproducibility\n",
    ")\n",
    "\n",
    "# Train the model with the scaled training data\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_pred = nn_model.predict(X_val)  # Assuming X_val is already scaled\n",
    "\n",
    "# Calculate F1-score and generate classification report\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "class_report = classification_report(y_val, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"F1 Score (Weighted): {f1:.2f}\")\n",
    "print(\"Classification Report for Validation Set:\\n\", class_report)\n",
    "\n",
    "test_results = nn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62206c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3197"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_precision = precision_score(y_val, y_pred, average='macro').round(4)\n",
    "nn_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d80555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_recall = recall_score(y_val, y_pred, average='macro').round(4)\n",
    "nn_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e8f03ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3208"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_f1 = f1_score(y_val, y_pred, average='macro').round(4)\n",
    "nn_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "885b45bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as nn_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"nn_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216a2d8-0e1d-4e46-a303-83d1e2b5eda1",
   "metadata": {},
   "source": [
    "## 6.6 Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14cd443a-d08f-4c4a-be90-b629ecbd7c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[610]\ttraining's multi_logloss: 0.478656\tvalid_1's multi_logloss: 0.627269\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.55      0.56      3743\n",
      "           2       0.86      0.94      0.90     87324\n",
      "           3       0.37      0.21      0.27     20672\n",
      "           4       0.77      0.73      0.75     44552\n",
      "           5       0.58      0.75      0.65     14484\n",
      "           6       0.15      0.08      0.10      1263\n",
      "           7       0.14      0.03      0.06        29\n",
      "           8       0.38      0.41      0.39       141\n",
      "\n",
      "    accuracy                           0.77    172208\n",
      "   macro avg       0.48      0.46      0.46    172208\n",
      "weighted avg       0.74      0.77      0.75    172208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform y_train and y_val\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# Create LightGBM Datasets with encoded classes\n",
    "train_data = lgb.Dataset(X_train, label=y_train_encoded)\n",
    "val_data = lgb.Dataset(X_val, label=y_val_encoded, reference=train_data)\n",
    "\n",
    "# Model hyperparameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(label_encoder.classes_),  # Use the actual number of classes\n",
    "    'metric': 'multi_logloss',  # Evaluation metric\n",
    "    'boosting_type': 'gbdt',  # Gradient Boosting Decision Tree\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Configure early stopping as a callback\n",
    "callbacks = [lgb.early_stopping(100)]  # Stop after 100 rounds with no improvement\n",
    "\n",
    "# Train the model with early stopping callback\n",
    "light_model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=callbacks  # Pass the early stopping callback\n",
    ")\n",
    "\n",
    "# Predict probabilities for the validation set\n",
    "y_pred_prob = light_model.predict(X_val, num_iteration=light_model.best_iteration)\n",
    "\n",
    "# Convert probabilities to predicted classes\n",
    "y_pred_classes = [list(x).index(max(x)) for x in y_pred_prob]\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "y_val_labels = label_encoder.inverse_transform(y_val_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_labels, y_pred_labels))\n",
    "\n",
    "test_results_prob = light_model.predict(X_test, num_iteration=light_model.best_iteration)\n",
    "\n",
    "# Convert probabilities to predicted class indices\n",
    "test_results_classes = [list(x).index(max(x)) for x in test_results_prob]\n",
    "\n",
    "# Convert class indices back to original labels using the LabelEncoder\n",
    "test_results = label_encoder.inverse_transform(test_results_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b4edfbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.477"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_precision = precision_score(y_val_encoded, y_pred_classes, average='macro').round(4)\n",
    "light_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ed1355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4627"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_recall = recall_score(y_val_encoded, y_pred_classes, average='macro').round(4)\n",
    "light_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "05ad2ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4599"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_f1 = f1_score(y_val_encoded, y_pred_classes, average='macro').round(4)\n",
    "light_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3825d922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387975,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d11a3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as light_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"light_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ccb65-fc4e-409d-bf27-c71dc0894b7f",
   "metadata": {},
   "source": [
    "## 6.7 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4bb2a3d-5e7d-4bb3-8243-9ce670bff6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mainj\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:32:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53      3743\n",
      "           1       0.86      0.94      0.90     87324\n",
      "           2       0.36      0.20      0.25     20672\n",
      "           3       0.77      0.71      0.74     44552\n",
      "           4       0.57      0.75      0.65     14484\n",
      "           5       0.16      0.15      0.15      1263\n",
      "           6       0.06      0.07      0.06        29\n",
      "           7       0.27      0.52      0.36       141\n",
      "\n",
      "    accuracy                           0.76    172208\n",
      "   macro avg       0.45      0.48      0.46    172208\n",
      "weighted avg       0.74      0.76      0.75    172208\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1999  1423   247    43    21     1     0     9]\n",
      " [ 1427 82451  2732   452   202    13     0    47]\n",
      " [  170  9881  4048  4963  1494    80     5    31]\n",
      " [  152  2127  3669 31490  6245   750    20    99]\n",
      " [    9    92   454  2957 10827   136     2     7]\n",
      " [    0     0    30   770   272   184     4     3]\n",
      " [    0     0     3    14     7     2     2     1]\n",
      " [    2    16    17    28     2     1     1    74]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Reindex classes to start from 0\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "# 2. Create the XGBoost model\n",
    "xg_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # For multiclass classification\n",
    "    num_class=8,                # Number of classes\n",
    "    eval_metric='mlogloss',     # Evaluation metric\n",
    "    use_label_encoder=False     # Disable XGBoost's label encoder\n",
    ")\n",
    "\n",
    "# 3. Train the model\n",
    "xg_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 4. Make predictions on the validation set\n",
    "y_pred_encoded = xg_model.predict(X_val)\n",
    "\n",
    "# 5. Decode predictions back to the original labels\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "\n",
    "# Classification report (precision, recall, f1-score for each class)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_encoded, y_pred_encoded))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val_encoded, y_pred_encoded)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "test_results = xg_model.predict(X_test)\n",
    "\n",
    "replacement_map = {i: i + 1 for i in range(8)}\n",
    "\n",
    "test_results = [replacement_map[val] for val in test_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bb2edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4479"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_precision = precision_score(y_val_encoded, y_pred_encoded, average='macro').round(4)\n",
    "xg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d44c8523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4835"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_recall = recall_score(y_val_encoded, y_pred_encoded, average='macro').round(4)\n",
    "xg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e225556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4556"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_f1 = f1_score(y_val_encoded, y_pred_encoded, average='macro').round(4)\n",
    "xg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00603491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as xg_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"xg_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc247fc-4790-4890-9863-61f4e8e78c75",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b462b5-adcc-4506-b66d-8ec007241ee5",
   "metadata": {},
   "source": [
    "It was tested the Voting Classifier in an attempt to improve the model, but the score was very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b90ccf88-ec9a-4153-a5e7-cae76b5abde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels after encoding: [0 1 2 3 4 5 6 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mainj\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:12:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Soft Voting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.61      0.46      3743\n",
      "           2       0.87      0.90      0.88     87324\n",
      "           3       0.34      0.21      0.26     20672\n",
      "           4       0.77      0.62      0.69     44552\n",
      "           5       0.51      0.78      0.62     14484\n",
      "           6       0.12      0.30      0.17      1263\n",
      "           7       0.01      0.14      0.02        29\n",
      "           8       0.10      0.73      0.18       141\n",
      "\n",
      "    accuracy                           0.72    172208\n",
      "   macro avg       0.39      0.54      0.41    172208\n",
      "weighted avg       0.73      0.72      0.72    172208\n",
      "\n",
      "F1-Score (Macro Average): 0.4099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Apply LabelEncoder to reindex labels to start from 0\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on y_train and transform y_train\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Now check the unique labels in y_train_encoded (should start from 0)\n",
    "print(f\"Unique labels after encoding: {np.unique(y_train_encoded)}\")\n",
    "\n",
    "# 2. Fit the XGBoost model with the encoded labels\n",
    "if not hasattr(xg_model, 'booster_'):\n",
    "    xg_model.fit(X_train, y_train_encoded)  # Fit using the encoded labels\n",
    "\n",
    "# 3. Now predict probabilities with the fitted model\n",
    "proba_rf = rf_model.predict_proba(X_val)  # Random Forest probabilities\n",
    "proba_lr = log_model.predict_proba(X_val)  # Logistic Regression probabilities\n",
    "proba_xgb = xg_model.predict_proba(X_val)  # XGBoost probabilities\n",
    "\n",
    "# 4. Combine the probabilities using Soft Voting (average of probabilities)\n",
    "soft_voting_proba = (proba_rf + proba_lr + proba_xgb) / 3  # Average probabilities\n",
    "\n",
    "# 5. Final prediction: class with highest summed probability\n",
    "soft_voting_preds = np.argmax(soft_voting_proba, axis=1)\n",
    "\n",
    "# 6. Decode the predictions back to the original labels\n",
    "y_pred = le.inverse_transform(soft_voting_preds)\n",
    "\n",
    "# 7. Evaluate the model (classification report without accuracy)\n",
    "print(\"Classification Report (Soft Voting):\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Optional: F1-score (macro average)\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "print(f\"F1-Score (Macro Average): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e86e4133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.4095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.3484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.3197</td>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.4627</td>\n",
       "      <td>0.4599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.4556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Precision  Recall  F1-Score\n",
       "0        Random Forest     0.3804  0.5205    0.4095\n",
       "1  Logistic Regression     0.2877  0.5224    0.2750\n",
       "2        Decision Tree     0.3349  0.3986    0.3484\n",
       "3          Naive Bayes     0.2617  0.3976    0.2069\n",
       "4       Neural Network     0.3197  0.5034    0.3208\n",
       "5             LightGBM     0.4770  0.4627    0.4599\n",
       "6              XGBoost     0.4479  0.4835    0.4556"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for the table\n",
    "data = {\n",
    "    'Model': [\n",
    "        'Random Forest', 'Logistic Regression', 'Decision Tree', \n",
    "        'Naive Bayes', 'Neural Network', 'LightGBM', 'XGBoost'\n",
    "    ],\n",
    "    'Precision': [\n",
    "        rf_precision, log_precision, dt_precision, nb_precision, nn_precision, \n",
    "        light_precision, xg_precision\n",
    "    ],\n",
    "    'Recall': [\n",
    "        rf_recall, log_recall, dt_recall, nb_recall, nn_recall, \n",
    "        light_recall, xg_recall\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        rf_f1, log_f1, dt_f1, nb_f1, nn_f1, \n",
    "        light_f1, xg_f1\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e44d4-e581-4060-acd0-df0cd806f3f4",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697eb3d9-1e54-41c8-9d02-cd3125a423ea",
   "metadata": {},
   "source": [
    "In addition to a few other models that we thought would provide superior performance, we tested five baseline models. We chose the two models with the greatest scores for additional optimization after analyzing the outcomes. We used cross-validation and grid search to improve their performance, which helped us optimize the hyperparameters and find the ideal values. By using this method, we were able to maximize the accuracy and overall performance of the model and attain better outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c1328-8cc7-4d48-b6dd-b50a9ebed7a0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce6421eb-63c9-47e8-aedd-3404afafeb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'bootstrap': False, 'class_weight': 'balanced', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 121}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "# Stratified sampling of 10% from resampled data\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(\n",
    "    X_train, y_train, test_size=0.9, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "# Define the RandomForestClassifier model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the Stratified K-Fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a randomized hyperparameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),       # Test between 100-500 trees\n",
    "    'max_depth': [10, 20, 30, None],         # Range for tree depth\n",
    "    'min_samples_split': [2, 5, 10],         # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],           # Minimum samples in a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],        # Feature selection strategies\n",
    "    'bootstrap': [True, False],              # Use bootstrap sampling\n",
    "    'class_weight': ['balanced']             # Handle class imbalance\n",
    "}\n",
    "\n",
    "# Set up the RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # Test 50 random combinations\n",
    "    scoring='f1_macro',  # Optimize for macro-averaged F1 score\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV to the sampled data (10%)\n",
    "random_search.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# Get the best model from RandomizedSearchCV\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4177c6bd-e8da-4e36-9d30-63efbdfa97ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 2126  1081   322   126    69     3     0    16]\n",
      " [ 2044 76661  6458  1578   495    16     0    72]\n",
      " [  238  8650  4933  4925  1752   126     2    46]\n",
      " [  213  2856  4367 28969  6941  1055     6   145]\n",
      " [   17    98   525  2757 10880   192     1    14]\n",
      " [    0     1    39   719   283   215     1     5]\n",
      " [    0     0     0    17     5     5     1     1]\n",
      " [    5     7    20    22     2     3     2    80]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.57      0.51      3743\n",
      "           2       0.86      0.88      0.87     87324\n",
      "           3       0.30      0.24      0.26     20672\n",
      "           4       0.74      0.65      0.69     44552\n",
      "           5       0.53      0.75      0.62     14484\n",
      "           6       0.13      0.17      0.15      1263\n",
      "           7       0.08      0.03      0.05        29\n",
      "           8       0.21      0.57      0.31       141\n",
      "\n",
      "    accuracy                           0.72    172208\n",
      "   macro avg       0.41      0.48      0.43    172208\n",
      "weighted avg       0.72      0.72      0.72    172208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters from RandomizedSearchCV\n",
    "best_params = {\n",
    "    'bootstrap': False,\n",
    "    'class_weight': 'balanced',\n",
    "    'max_depth': None,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 5,\n",
    "    'n_estimators': 121\n",
    "}\n",
    "\n",
    "# Create the model with the best hyperparameters\n",
    "grid_rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "\n",
    "# Train the model on the full training data\n",
    "grid_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = grid_rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "class_report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "test_results = grid_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a21fcee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4133"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_precision = precision_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_rf_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0dc873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4823"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_recall = recall_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_rf_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f43fa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4325"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_f1 = f1_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "feacee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as grid_rf_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"grid_rf_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2820e97b-226e-48c9-98e5-c68e565f0a9b",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "510e15b0-9907-4d07-8b49-8177cb4a8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best parameters found: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 150, 'subsample': 0.8}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49      3743\n",
      "           1       0.85      0.93      0.89     87324\n",
      "           2       0.31      0.18      0.23     20672\n",
      "           3       0.75      0.68      0.72     44552\n",
      "           4       0.55      0.71      0.62     14484\n",
      "           5       0.13      0.16      0.15      1263\n",
      "           6       0.01      0.03      0.02        29\n",
      "           7       0.19      0.58      0.28       141\n",
      "\n",
      "    accuracy                           0.74    172208\n",
      "   macro avg       0.41      0.47      0.42    172208\n",
      "weighted avg       0.72      0.74      0.73    172208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Reduce dataset size to 10% for faster experimentation\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(\n",
    "    X_train, y_train, train_size=0.1, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# 2. Reindex classes to start from 0\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_sampled)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "# 3. Define the LightGBM model\n",
    "model = LGBMClassifier(\n",
    "    objective='multiclass', \n",
    "    num_class=len(le.classes_), \n",
    "    metric='multi_logloss',  # Log-loss is often used in multiclass classification\n",
    "    verbose=-1              # Reduce verbosity\n",
    ")\n",
    "\n",
    "# 4. Define the parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],  # Learning rate options\n",
    "    'n_estimators': [100, 150],    # Number of estimators (trees)\n",
    "    'max_depth': [6, 10],          # Max depth of the trees\n",
    "    'subsample': [0.8, 1.0],       # Subsampling ratio\n",
    "    'colsample_bytree': [0.8]      # Feature subsampling ratio\n",
    "}\n",
    "\n",
    "# 5. GridSearchCV with 3-fold cross-validation (for faster search)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    scoring='f1_macro',  # Maximize the macro average F1-Score\n",
    "    cv=3,                # 3-fold cross-validation to save time\n",
    "    n_jobs=-1,           # Use all available processors\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 6. Train the model with GridSearchCV\n",
    "grid_search.fit(X_train_sampled, y_train_encoded)\n",
    "\n",
    "# 7. Best parameter set found\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# 8. Evaluate the model with the best parameters found\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 9. Make predictions on the validation set (assuming X_val and y_val are available)\n",
    "y_pred_encoded = best_model.predict(X_val)\n",
    "\n",
    "# 10. Evaluate the model\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_encoded, y_pred_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "177f6c7c-0dd1-4b90-936d-e20a5ffb39d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.53      0.54      3743\n",
      "           2       0.86      0.95      0.90     87324\n",
      "           3       0.38      0.18      0.25     20672\n",
      "           4       0.77      0.72      0.75     44552\n",
      "           5       0.57      0.75      0.65     14484\n",
      "           6       0.17      0.12      0.14      1263\n",
      "           7       0.03      0.03      0.03        29\n",
      "           8       0.29      0.49      0.36       141\n",
      "\n",
      "    accuracy                           0.77    172208\n",
      "   macro avg       0.45      0.47      0.45    172208\n",
      "weighted avg       0.74      0.77      0.75    172208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# 1. Definir o modelo com os melhores parâmetros\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 150,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "\n",
    "grid_light_model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=len(y_train.unique()),  # Garantir que todas as classes sejam consideradas\n",
    "    metric='multi_logloss',\n",
    "    verbose=-1,\n",
    "    random_state=42,\n",
    "    **best_params  # Usar os melhores parâmetros encontrados\n",
    ")\n",
    "\n",
    "# 2. Reindexar as classes no conjunto de treino completo\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "# 3. Treinar o modelo no conjunto de treino completo\n",
    "grid_light_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 4. Fazer predições no conjunto de validação\n",
    "y_pred_encoded = grid_light_model.predict(X_val)\n",
    "\n",
    "# 5. Decodificar as predições para as classes originais\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Relatório de classificação completo\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "test_results_prob = light_model.predict(X_test, num_iteration=light_model.best_iteration)\n",
    "\n",
    "# Convert probabilities to predicted class indices\n",
    "test_results_classes = [list(x).index(max(x)) for x in test_results_prob]\n",
    "\n",
    "# Convert class indices back to original labels using the LabelEncoder\n",
    "test_results = label_encoder.inverse_transform(test_results_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac415d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4521"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_light_precision = precision_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_light_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0dfdc8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4727"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_light_recall = recall_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_light_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fcbeeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4524"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_light_f1 = f1_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_light_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ff16760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as grid_light_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"grid_light_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbb627-52e6-40a1-b19b-4aeb296a2d04",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76716f2d-bac7-4eef-84b0-1e08c9dd07fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "Best parameters found: {'colsample_bytree': 0.7, 'gamma': 0.1, 'learning_rate': 0.3, 'max_depth': 6, 'n_estimators': 150, 'reg_alpha': 0, 'reg_lambda': 1.5, 'subsample': 0.8}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.50      0.50      3743\n",
      "           2       0.86      0.91      0.88     87324\n",
      "           3       0.29      0.22      0.25     20672\n",
      "           4       0.75      0.65      0.69     44552\n",
      "           5       0.55      0.69      0.61     14484\n",
      "           6       0.13      0.18      0.15      1263\n",
      "           7       0.02      0.07      0.04        29\n",
      "           8       0.18      0.61      0.28       141\n",
      "\n",
      "    accuracy                           0.73    172208\n",
      "   macro avg       0.41      0.48      0.43    172208\n",
      "weighted avg       0.72      0.73      0.72    172208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Reduce dataset size to 10% for faster experimentation\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(\n",
    "    X_train, y_train, train_size=0.1, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# 2. Reindex classes to start from 0\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_sampled)\n",
    "\n",
    "# 3. Define the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax', \n",
    "    num_class=len(le.classes_), \n",
    "    use_label_encoder=False,\n",
    "    tree_method='hist',   # Optimized for large datasets\n",
    "    verbosity=0           # Reduce output verbosity\n",
    ")\n",
    "\n",
    "# 4. Define the parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'max_depth': [6, 10],         # Add more depth options for optimization\n",
    "    'learning_rate': [0.1, 0.2, 0.3],  # Include smaller and larger learning rates\n",
    "    'n_estimators': [100, 150],     # Test with more estimators\n",
    "    'subsample': [0.8, 0.9],        # Subsampling ratio\n",
    "    'colsample_bytree': [0.7, 0.8], # Feature subsampling ratio\n",
    "    'gamma': [0, 0.1],         # Minimum loss reduction for further partitioning\n",
    "    'reg_lambda': [1, 1.5],         # L2 regularization\n",
    "    'reg_alpha': [0, 0.5]           # L1 regularization\n",
    "}\n",
    "\n",
    "# 5. GridSearchCV with 3-fold cross-validation (to save time and resources)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid, \n",
    "    scoring='f1_macro',  # Maximize macro average F1-Score\n",
    "    cv=3,                # 3-fold for faster grid search\n",
    "    n_jobs=-1,           # Use all processors\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 6. Train the model with GridSearchCV\n",
    "grid_search.fit(X_train_sampled, y_train_encoded)\n",
    "\n",
    "# 7. Best parameter set found\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# 8. Evaluate the model with the best parameters found\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 9. Make predictions on the validation set (assuming X_val and y_val are available)\n",
    "y_pred_encoded = best_model.predict(X_val)\n",
    "\n",
    "# 10. Decode predictions back to the original labels\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# 11. Evaluate the model\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "997011eb-c62c-489f-b4f7-ccb186064a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mainj\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:31:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.54      0.54      3743\n",
      "           2       0.86      0.94      0.90     87324\n",
      "           3       0.36      0.20      0.26     20672\n",
      "           4       0.77      0.71      0.74     44552\n",
      "           5       0.57      0.75      0.65     14484\n",
      "           6       0.17      0.13      0.15      1263\n",
      "           7       0.06      0.03      0.04        29\n",
      "           8       0.32      0.50      0.39       141\n",
      "\n",
      "    accuracy                           0.76    172208\n",
      "   macro avg       0.46      0.48      0.46    172208\n",
      "weighted avg       0.74      0.76      0.75    172208\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2026  1408   235    49    18     1     0     6]\n",
      " [ 1388 82324  2876   501   191     9     0    35]\n",
      " [  156  9739  4221  5013  1449    66     2    26]\n",
      " [  141  2027  3856 31746  6081   612     8    81]\n",
      " [   11    90   429  3048 10792   111     1     2]\n",
      " [    0     0    32   783   282   163     2     1]\n",
      " [    0     0     2    15     7     3     1     1]\n",
      " [    0    18    12    37     1     0     2    71]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Reindex classes to start from 0\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "# 2. Create the XGBoost model with predefined parameters\n",
    "grid_xg_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # For multiclass classification\n",
    "    num_class=8,                # Number of classes\n",
    "    eval_metric='mlogloss',     # Evaluation metric\n",
    "    use_label_encoder=False,    # Disable XGBoost's label encoder\n",
    "    colsample_bytree=0.7,       # Feature subsampling ratio\n",
    "    gamma=0.1,                  # Minimum loss reduction for further partitioning\n",
    "    learning_rate=0.3,          # Learning rate\n",
    "    max_depth=6,                # Maximum tree depth\n",
    "    n_estimators=150,           # Number of trees\n",
    "    reg_alpha=0,                # L1 regularization\n",
    "    reg_lambda=1.5,             # L2 regularization\n",
    "    subsample=0.8               # Subsampling ratio\n",
    ")\n",
    "\n",
    "# 3. Train the grid_xg_model\n",
    "grid_xg_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# 4. Make predictions on the validation set\n",
    "y_pred_encoded = grid_xg_model.predict(X_val)\n",
    "\n",
    "# 5. Decode predictions back to the original labels\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "\n",
    "# Classification report (precision, recall, f1-score for each class)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "test_results = grid_xg_model.predict(X_test)\n",
    "\n",
    "replacement_map = {i: i + 1 for i in range(8)}\n",
    "\n",
    "test_results = [replacement_map[val] for val in test_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27fa32ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4577"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xg_precision = precision_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_xg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21ed33c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4766"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xg_recall = recall_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_xg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22e7c377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4592"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xg_f1 = f1_score(y_val, y_pred, average='macro').round(4)\n",
    "grid_xg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f144fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exported successfully as grid_xg_model.csv\n"
     ]
    }
   ],
   "source": [
    "export_predictions(test_results, X_test_original, \"grid_xg_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18202c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_kaggle = 0.32603\n",
    "log_kaggle = 0.19487\n",
    "dt_kaggle = 0.24308\n",
    "nb_kaggle = 0.16755\n",
    "nn_kaggle = 0.24528\n",
    "light_kaggle = 0.41025\n",
    "xg_kaggle = 0.39258\n",
    "grid_rf_kaggle = 0.34096\n",
    "grid_light_kaggle = 0.41025\n",
    "grid_xg_kaggle = 0.40752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff0db2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Kaggle Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.4095</td>\n",
       "      <td>0.32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.19487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.24308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.16755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.3197</td>\n",
       "      <td>0.5034</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>0.24528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.4627</td>\n",
       "      <td>0.4599</td>\n",
       "      <td>0.41025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.4556</td>\n",
       "      <td>0.39258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grid Search Random Forest</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.4823</td>\n",
       "      <td>0.4325</td>\n",
       "      <td>0.34096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grid Search LightGBM</td>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.4524</td>\n",
       "      <td>0.41025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grid Search XGBoost</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.40752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Precision  Recall  F1-Score  Kaggle Score\n",
       "0              Random Forest     0.3804  0.5205    0.4095       0.32603\n",
       "1        Logistic Regression     0.2877  0.5224    0.2750       0.19487\n",
       "2              Decision Tree     0.3349  0.3986    0.3484       0.24308\n",
       "3                Naive Bayes     0.2617  0.3976    0.2069       0.16755\n",
       "4             Neural Network     0.3197  0.5034    0.3208       0.24528\n",
       "5                   LightGBM     0.4770  0.4627    0.4599       0.41025\n",
       "6                    XGBoost     0.4479  0.4835    0.4556       0.39258\n",
       "7  Grid Search Random Forest     0.4133  0.4823    0.4325       0.34096\n",
       "8       Grid Search LightGBM     0.4521  0.4727    0.4524       0.41025\n",
       "9        Grid Search XGBoost     0.4577  0.4766    0.4592       0.40752"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for the table\n",
    "data = {\n",
    "    'Model': [\n",
    "        'Random Forest', 'Logistic Regression', 'Decision Tree', \n",
    "        'Naive Bayes', 'Neural Network', 'LightGBM', 'XGBoost',\n",
    "        'Grid Search Random Forest', 'Grid Search LightGBM', 'Grid Search XGBoost'\n",
    "    ],\n",
    "    'Precision': [\n",
    "        rf_precision, log_precision, dt_precision, nb_precision, nn_precision, \n",
    "        light_precision, xg_precision,\n",
    "        grid_rf_precision, grid_light_precision, grid_xg_precision\n",
    "    ],\n",
    "    'Recall': [\n",
    "        rf_recall, log_recall, dt_recall, nb_recall, nn_recall, \n",
    "        light_recall, xg_recall,\n",
    "        grid_rf_recall, grid_light_recall, grid_xg_recall\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        rf_f1, log_f1, dt_f1, nb_f1, nn_f1, \n",
    "        light_f1, xg_f1,\n",
    "        grid_rf_f1, grid_light_f1, grid_xg_f1\n",
    "    ],\n",
    "    'Kaggle Score': [\n",
    "        rf_kaggle, log_kaggle, dt_kaggle, nb_kaggle,\n",
    "        nn_kaggle, light_kaggle, xg_kaggle, grid_rf_kaggle,\n",
    "        grid_light_kaggle, grid_xg_kaggle\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e04e8-7bdf-421d-9dfc-358deab684bf",
   "metadata": {},
   "source": [
    "# 7.Final Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81645e-4d10-436b-9976-84e7bcb85b3f",
   "metadata": {},
   "source": [
    "Our best model is `LightGBM`, based on all metrics, having the best *Precision* and best *F1-Score Macro*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "737cbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = light_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fd735623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully exported as model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "joblib.dump(grid_rf_model, 'model.pkl')\n",
    "\n",
    "print(\"Model successfully exported as model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
